{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import datetime\n",
    "from utils import *\n",
    "from data_processing import *\n",
    "today = datetime.date.today()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_cmapss(TsConf.input_url)\n",
    "feat_names = df.columns.values[3:-1]\n",
    "target_name = df.columns.values[-1]\n",
    "df[feat_names] = data_norm(df[feat_names])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_feat = [\"Total temp at HPC out (T30)\", \n",
    "               \"Total temp at LPT out (T50)\", \n",
    "               \"Physical core speed (Nc)\", \n",
    "               \"Static pres at HPC out (Ps30)\", \n",
    "               \"Corrected core speed (NRc)\", \n",
    "               \"Bypass Ratio (BPR)\", \n",
    "               \"Bleed Enthalpy (htBleed)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df[([\"FILEID\",\"ENGINEID\", \"TIMECYCLE\"]+select_feat+[\"RUL\"])][df.FILEID.isin(TsConf.train_fids)]\n",
    "test = df[([\"FILEID\",\"ENGINEID\", \"TIMECYCLE\"]+select_feat+[\"RUL\"])][df.FILEID.isin(TsConf.test_fids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FILEID</th>\n",
       "      <th>ENGINEID</th>\n",
       "      <th>TIMECYCLE</th>\n",
       "      <th>Total temp at HPC out (T30)</th>\n",
       "      <th>Total temp at LPT out (T50)</th>\n",
       "      <th>Physical core speed (Nc)</th>\n",
       "      <th>Static pres at HPC out (Ps30)</th>\n",
       "      <th>Corrected core speed (NRc)</th>\n",
       "      <th>Bypass Ratio (BPR)</th>\n",
       "      <th>Bleed Enthalpy (htBleed)</th>\n",
       "      <th>RUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20626</th>\n",
       "      <td>101</td>\n",
       "      <td>100</td>\n",
       "      <td>196</td>\n",
       "      <td>1.116880</td>\n",
       "      <td>1.242910</td>\n",
       "      <td>1.043518</td>\n",
       "      <td>1.141351</td>\n",
       "      <td>0.629226</td>\n",
       "      <td>-0.740904</td>\n",
       "      <td>1.179266</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20627</th>\n",
       "      <td>101</td>\n",
       "      <td>100</td>\n",
       "      <td>197</td>\n",
       "      <td>1.172109</td>\n",
       "      <td>1.279284</td>\n",
       "      <td>1.042422</td>\n",
       "      <td>1.132578</td>\n",
       "      <td>0.615475</td>\n",
       "      <td>-0.716515</td>\n",
       "      <td>1.114725</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20628</th>\n",
       "      <td>101</td>\n",
       "      <td>100</td>\n",
       "      <td>198</td>\n",
       "      <td>1.154829</td>\n",
       "      <td>1.239603</td>\n",
       "      <td>1.044534</td>\n",
       "      <td>1.147200</td>\n",
       "      <td>0.672353</td>\n",
       "      <td>-0.648944</td>\n",
       "      <td>1.211537</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20629</th>\n",
       "      <td>101</td>\n",
       "      <td>100</td>\n",
       "      <td>199</td>\n",
       "      <td>1.178547</td>\n",
       "      <td>1.227479</td>\n",
       "      <td>1.065438</td>\n",
       "      <td>1.234927</td>\n",
       "      <td>0.650352</td>\n",
       "      <td>-0.683196</td>\n",
       "      <td>1.114725</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20630</th>\n",
       "      <td>101</td>\n",
       "      <td>100</td>\n",
       "      <td>200</td>\n",
       "      <td>1.137210</td>\n",
       "      <td>1.268703</td>\n",
       "      <td>1.032719</td>\n",
       "      <td>1.179366</td>\n",
       "      <td>0.625850</td>\n",
       "      <td>-0.730242</td>\n",
       "      <td>1.146996</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       FILEID  ENGINEID  TIMECYCLE  Total temp at HPC out (T30)  \\\n",
       "20626     101       100        196                     1.116880   \n",
       "20627     101       100        197                     1.172109   \n",
       "20628     101       100        198                     1.154829   \n",
       "20629     101       100        199                     1.178547   \n",
       "20630     101       100        200                     1.137210   \n",
       "\n",
       "       Total temp at LPT out (T50)  Physical core speed (Nc)  \\\n",
       "20626                     1.242910                  1.043518   \n",
       "20627                     1.279284                  1.042422   \n",
       "20628                     1.239603                  1.044534   \n",
       "20629                     1.227479                  1.065438   \n",
       "20630                     1.268703                  1.032719   \n",
       "\n",
       "       Static pres at HPC out (Ps30)  Corrected core speed (NRc)  \\\n",
       "20626                       1.141351                    0.629226   \n",
       "20627                       1.132578                    0.615475   \n",
       "20628                       1.147200                    0.672353   \n",
       "20629                       1.234927                    0.650352   \n",
       "20630                       1.179366                    0.625850   \n",
       "\n",
       "       Bypass Ratio (BPR)  Bleed Enthalpy (htBleed)  RUL  \n",
       "20626           -0.740904                  1.179266    4  \n",
       "20627           -0.716515                  1.114725    3  \n",
       "20628           -0.648944                  1.211537    2  \n",
       "20629           -0.683196                  1.114725    1  \n",
       "20630           -0.730242                  1.146996    0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM (Sibur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train = TsDataFrame(train)\n",
    "test = TsDataFrame(test)\n",
    "n_eng_train = max(train.ENGINEID)\n",
    "n_eng_test = max(test.ENGINEID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.target = TsConf.target\n",
    "train.groupids = TsConf.groupids\n",
    "train.timestamp = TsConf.timestamp\n",
    "test.target = TsConf.target\n",
    "test.groupids = TsConf.groupids\n",
    "test.timestamp = TsConf.timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "    config = TsConf(train.columns)\n",
    "    Train = True\n",
    "    Predict = True\n",
    "    mode = \"Train\""
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "class TsLSTM():\n",
    "    \"\"\"Encapsulates the Mask RCNN model functionality.\n",
    "    The actual Keras model is in the keras_model property.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, mode, config, model_dir):\n",
    "        \"\"\"\n",
    "        mode: Either \"training\" or \"inference\"\n",
    "        config: A Sub-class of the Config class\n",
    "        model_dir: Directory to save training logs and trained weights\n",
    "        \"\"\"\n",
    "        assert mode in ['training', 'inference']\n",
    "        self.mode = mode\n",
    "        self.config = config\n",
    "        self.model_dir = model_dir\n",
    "        self.set_log_dir()\n",
    "        self.model = self.build(mode=mode, config=config)\n",
    "\n",
    "    def build(self, mode, config):\n",
    "        print (\"build\")\n",
    "        \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My Conv Shape: [None, 30, 7]\n"
     ]
    }
   ],
   "source": [
    "        X = tf.placeholder(tf.float32, [None, config.sequence_length, config.n_channels], name='inputs')\n",
    "        Y = tf.placeholder(tf.float32, [None, config.sequence_length], name='labels')\n",
    "        keep_prob = tf.placeholder(tf.float32, name='keep_prob')\n",
    "        learning_rate_ = tf.placeholder(tf.float32, name='learning_rate')\n",
    "        is_train = tf.placeholder(dtype=tf.bool, shape=None, name=\"is_train\")\n",
    "\n",
    "        conv_last_layer = X\n",
    "\n",
    "        shape = conv_last_layer.get_shape().as_list()\n",
    "        print('My Conv Shape:',shape)\n",
    "        CNN_flat = tf.reshape(conv_last_layer, [-1, shape[1] * shape[2]])\n",
    "\n",
    "        dence_layer_1 = dense_layer(CNN_flat, size=config.sequence_length * config.n_channels, activation_fn=tf.nn.relu, batch_norm=False,\n",
    "                                    phase=is_train, drop_out=True, keep_prob=keep_prob,\n",
    "                                    scope=\"fc_1\")\n",
    "        lstm_input = tf.reshape(dence_layer_1, [-1, config.sequence_length, config.n_channels])\n",
    "\n",
    "        cell = get_RNNCell(['LSTM'] * config.num_layers, keep_prob=keep_prob, state_size=config.lstm_size)\n",
    "        init_states = cell.zero_state(config.batch_size, tf.float32)\n",
    "\n",
    "        # For each layer, get the initial state. states will be a tuple of LSTMStateTuples.\n",
    "        states = get_state_variables(config.batch_size, cell)\n",
    "\n",
    "        # Unroll the LSTM\n",
    "        rnn_output, new_states = tf.nn.dynamic_rnn(cell, lstm_input, dtype=tf.float32, initial_state=states)\n",
    "\n",
    "        # Add an operation to update the train states with the last state tensors.\n",
    "        update_op = get_state_update_op(states, new_states)\n",
    "        reset_op = get_state_update_op(states, init_states)\n",
    "\n",
    "        stacked_rnn_output = tf.reshape(rnn_output, [-1, config.lstm_size])  # change the form into a tensor\n",
    "\n",
    "        dence_layer_2 = dense_layer(stacked_rnn_output, size=config.ann_hidden, activation_fn=tf.nn.relu, batch_norm=False,\n",
    "                                    phase=is_train, drop_out=True, keep_prob=keep_prob,\n",
    "                                    scope=\"fc_2\")\n",
    "\n",
    "        dence_layer_3 = dense_layer(dence_layer_2, size=config.ann_hidden, activation_fn=tf.nn.relu, batch_norm=False,\n",
    "                                    phase=is_train, drop_out=True, keep_prob=keep_prob,\n",
    "                                    scope=\"fc_2_2\")\n",
    "\n",
    "        output = dense_layer(dence_layer_3, size=1, activation_fn=None, batch_norm=False, phase=is_train, drop_out=False,\n",
    "                             keep_prob=keep_prob,\n",
    "                             scope=\"fc_3_output\")\n",
    "\n",
    "        prediction = tf.reshape(output, [-1])\n",
    "        y_flat = tf.reshape(Y, [-1])\n",
    "\n",
    "        h = prediction - y_flat\n",
    "\n",
    "        tv = tf.trainable_variables()\n",
    "        regularization_cost = tf.reduce_sum([ tf.nn.l2_loss(v) for v in tv ])\n",
    "\n",
    "        cost_function = tf.reduce_sum(tf.square(h)) + config.alpha*regularization_cost\n",
    "        RMSE = tf.sqrt(tf.reduce_mean(tf.square(h)))\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate_).minimize(cost_function)\n",
    "\n",
    "        saver = tf.train.Saver()\n",
    "\n",
    "\n",
    "        if mode==\"Train\": model_summary(learning_rate=config.learning_rate, batch_size=config.batch_size, lstm_layers=config.num_layers,\n",
    "                                lstm_layer_size=config.lstm_size, fc_layer_size=config.ann_hidden, sequence_length=config.sequence_length,\n",
    "                                n_channels=config.n_channels, path_checkpoint=config.path_checkpoint, spacial_note='')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./save/save_lstm/lstm_2_layers\n",
      "Model restored from file: ./save/save_lstm/lstm_2_layers\n",
      "Training set MSE\n",
      "No epoches:  1000 No itr:  20631\n",
      "eng_id:  1.0   RMSE train: 17.691248\n",
      "eng_id:  2.0   RMSE train: 15.986529\n",
      "eng_id:  3.0   RMSE train: 19.306723\n",
      "eng_id:  4.0   RMSE train: 19.554493\n",
      "eng_id:  5.0   RMSE train: 18.284733\n",
      "eng_id:  6.0   RMSE train: 17.5273\n",
      "eng_id:  7.0   RMSE train: 17.108736\n",
      "eng_id:  8.0   RMSE train: 16.978357\n",
      "eng_id:  9.0   RMSE train: 17.518353\n",
      "eng_id:  10.0   RMSE train: 17.322283\n",
      "eng_id:  11.0   RMSE train: 16.83658\n",
      "eng_id:  12.0   RMSE train: 16.50655\n",
      "eng_id:  13.0   RMSE train: 16.339832\n",
      "eng_id:  14.0   RMSE train: 16.19517\n",
      "eng_id:  15.0   RMSE train: 15.989662\n",
      "eng_id:  16.0   RMSE train: 15.835707\n",
      "eng_id:  17.0   RMSE train: 15.545993\n",
      "eng_id:  18.0   RMSE train: 15.42515\n",
      "eng_id:  19.0   RMSE train: 15.33781\n",
      "eng_id:  20.0   RMSE train: 15.349435\n",
      "eng_id:  21.0   RMSE train: 15.205851\n",
      "eng_id:  22.0   RMSE train: 15.110872\n",
      "eng_id:  23.0   RMSE train: 15.048157\n",
      "eng_id:  24.0   RMSE train: 14.988629\n",
      "eng_id:  25.0   RMSE train: 15.010793\n",
      "eng_id:  26.0   RMSE train: 14.891785\n"
     ]
    }
   ],
   "source": [
    "    with tf.Session() as session:\n",
    "        tf.global_variables_initializer().run()\n",
    "\n",
    "        if Train == True:\n",
    "            saver.restore(session, config.path_checkpoint)\n",
    "            print(\"Model restored from file: %s\" % config.path_checkpoint)\n",
    "\n",
    "            cost = []\n",
    "            plot_x = []\n",
    "            plot_y1 = []\n",
    "            plot_y2 = []\n",
    "            iter_train = int(train.shape[0]/config.shift)\n",
    "            iter_test = int(test.shape[0]/config.shift)\n",
    "            print(\"Training set MSE\")\n",
    "            print(\"No epoches: \", config.epochs, \"No itr: \", iter_train)\n",
    "            __start = time.time()\n",
    "            for ep in range(config.epochs):\n",
    "                session.run(reset_op)\n",
    "                training_generator = train.endless_batch(config.sequence_length, config.shift, config.batch_size)\n",
    "                testing_generator = test.endless_batch(config.sequence_length, config.shift, config.batch_size)\n",
    "                \n",
    "                h1 = []\n",
    "                t1 = []\n",
    "                engine_id = 1\n",
    "           \n",
    "                while engine_id < n_eng_train:\n",
    "                    ## training ##\n",
    "                    train_gen = next(training_generator)\n",
    "                    batch_x, batch_y = train_gen[1], train_gen[2]                   \n",
    "                    session.run([optimizer, update_op],\n",
    "                                feed_dict={X: batch_x, Y: batch_y, keep_prob: 0.7, learning_rate_: config.learning_rate})\n",
    "                    h_i = h.eval(feed_dict={X: batch_x, Y: batch_y, keep_prob: 1.0, learning_rate_: config.learning_rate})\n",
    "                    cost.append(np.square(h_i))\n",
    "                    h1.append(h_i)\n",
    "                    \n",
    "                    if batch_y[0,-1] == 0: #\"RUL==0 end of current timeseries\"\n",
    "                        session.run(reset_op)\n",
    "                        engine_id = train_gen[0][0,0,1]\n",
    "                        print (\"eng_id: \",engine_id, \"  RMSE train:\", np.sqrt(np.mean(np.square(h1))))\n",
    "\n",
    "                rmse_train = np.sqrt(np.mean(np.square(h1)))\n",
    "\n",
    "                save_path = saver.save(session, config.path_checkpoint)\n",
    "                if os.path.exists(config.path_checkpoint + '.meta'):\n",
    "                    print(\"Model saved to file: %s\" % config.path_checkpoint)\n",
    "                else:\n",
    "                    print(\"NOT SAVED!!!\", config.path_checkpoint)\n",
    "                \n",
    "                y_pred = []\n",
    "                \n",
    "                try:\n",
    "                    while True:\n",
    "                        test_gen = next(testing_generator)\n",
    "                        x_test_batch, y_test_batch = test_gen[1], test_gen[2]\n",
    "                        h_i, u = session.run([h, update_op], feed_dict={X: x_test_batch, Y: y_test_batch, keep_prob: 1.0, \n",
    "                                                                        learning_rate_: config.learning_rate})\n",
    "                        t1.append(h_i)\n",
    "                except StopIteration:\n",
    "                    pass\n",
    "                \n",
    "                rmse_test = np.sqrt(np.mean(np.square(t1)))\n",
    "\n",
    "                plot_x.append(ep)\n",
    "                plot_y1.append(rmse_train)\n",
    "                plot_y2.append(rmse_test)\n",
    "\n",
    "                time_per_ep = (time.time() - __start)\n",
    "                time_remaining = ((config.epochs - ep) * time_per_ep) / 3600\n",
    "                print(\"LSTM\", \"epoch:\", ep, \"RMSE-train:\", rmse_train, \"RMSE-test\", rmse_test, \"lr\", config.learning_rate,\n",
    "                      \"\\ttime/epoch:\", round(time_per_ep, 2), \"\\ttime_remaining: \",\n",
    "                      int(time_remaining), \" hr:\", round((time_remaining % 1) * 60, 1), \" min\", \"\\ttime_stamp: \",\n",
    "                      datetime.datetime.now().strftime(\"%Y.%m.%d-%H:%M:%S\"))\n",
    "                __start = time.time()\n",
    "                \n",
    "                if ep % 50 == 0 and ep != 0: \n",
    "                    plt.plot(plot_x, plot_y1, 'bo', plot_x, plot_y2, 'go')\n",
    "                    plt.show()\n",
    "                        \n",
    "                if ep % 100 == 0 and ep != 0: \n",
    "                    config.learning_rate = config.learning_rate / 2\n",
    "\n",
    "\n",
    "            save_path = saver.save(session, config.path_checkpoint)\n",
    "            if os.path.exists(path_checkpoint + '.meta'):\n",
    "                print(\"Model saved to file: %s\" % path_checkpoint)\n",
    "            else:\n",
    "                print(\"NOT SAVED!!!\", path_checkpoint)\n",
    "            plt.plot(plot_x, plot_y1, 'bo', plot_x, plot_y2, 'go')\n",
    "            plt.show()\n",
    "        else:\n",
    "            saver.restore(session, config.path_checkpoint)\n",
    "            print(\"Model restored from file: %s\" % config.path_checkpoint)\n",
    "            if Predict == True:\n",
    "                print(\"Prediction for submit...\")\n",
    "                x_predict = Xs\n",
    "                y_predict = np.zeros((Xs.shape[0],Xs.shape[1]))\n",
    "\n",
    "                predict_generator = batch_generator(x_predict, y_predict, config.batch_size, config.sequence_length,\n",
    "                                                       online=True, online_shift=config.shift)\n",
    "\n",
    "                full_prediction = []\n",
    "\n",
    "                iteration = int(x_predict.shape[0] / config.shift)\n",
    "                #print(\"iteration: %i, predgen %s\" % (iteration, predict_generator))\n",
    "                print(\"#of validation points:\", x_predict.shape[0], \"#datapoints covers from minibatch:\",\n",
    "                      config.batch_size * config.sequence_length, \"iterations/epoch\", iteration)\n",
    "\n",
    "                for itr in range(iteration):\n",
    "                    x_validate_batch, y_validate_batch = next(predict_generator)\n",
    "                    #print (itr)\n",
    "                    __y_pred, u = session.run([output, update_op], feed_dict={X: x_validate_batch, Y: y_validate_batch, keep_prob: 1.0})\n",
    "                    #session.run(update_op)\n",
    "                    for i in range(config.batch_size):\n",
    "                        full_prediction.append(__y_pred[i*config.sequence_length])\n",
    "                    #print(__y_pred.shape)\n",
    "                    \n",
    "                full_prediction = np.array(full_prediction)\n",
    "                full_prediction = full_prediction.ravel()\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_submit = full_prediction*std_y+mean_y\n",
    "sub_file = pd.DataFrame()\n",
    "sub_file[\"timestamp\"] = submit_X.index[-2872:]\n",
    "sub_file[\"target\"] = y_submit[-2872:]\n",
    "sub_file.to_csv('submit2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TS fresh dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add_lag_roll(test.iloc[:,:-2], feat_names, lag=lag, step=step, roll=0).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.groupby([\"FILEID\", \"ENGINEID\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X=pd.DataFrame()\n",
    "#y=list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for name, group in df.groupby([\"FILEID\", \"ENGINEID\"]):\n",
    "    #X = pd.concat([X, add_lag_roll(group[feat_names], feat_names, lag=lag, step=step)], axis=0)\n",
    "    #y = y.append(group[\"RUL\"][lag:])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X.tail(1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
