{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import datetime\n",
    "from utils import *\n",
    "from data_processing import *\n",
    "today = datetime.date.today()\n",
    "input_url = \"input/dataset.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def series_to_supervised(data, n_in=1, n_out=1, periods=5, dropnan=True):\n",
    "\t\"\"\"\n",
    "\tFrame a time series as a supervised learning dataset.\n",
    "\tArguments:\n",
    "\t\tdata: Sequence of observations as a list or NumPy array.\n",
    "\t\tn_in: Number of lag observations as input (X).\n",
    "\t\tn_out: Number of observations as output (y).\n",
    "\t\tdropnan: Boolean whether or not to drop rows with NaN values.\n",
    "\tReturns:\n",
    "\t\tPandas DataFrame of series framed for supervised learning.\n",
    "\t\"\"\"\n",
    "\tn_vars = 1 if type(data) is list else data.shape[1]\n",
    "\tdf = pd.DataFrame(data)\n",
    "\tcols, names = list(), list()\n",
    "\t# input sequence (t-n, ... t-1)\n",
    "\tfor i in range(n_in//periods, 0, -1):\n",
    "\t\tcols.append(df.shift(i*periods)-df)\n",
    "\t\tnames += [('var%d(t-%d)' % (j+1, i*periods)) for j in range(n_vars)]\n",
    "\t# forecast sequence (t, t+1, ... t+n)\n",
    "\tfor i in range(0, n_out//periods):\n",
    "\t\tcols.append(df.shift(-i*periods)-df)\n",
    "\t\tif i == 0:\n",
    "\t\t\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "\t\telse:\n",
    "\t\t\tnames += [('var%d(t+%d)' % (j+1, i*periods)) for j in range(n_vars)]\n",
    "\t# put it all together\n",
    "\tagg = pd.concat(cols, axis=1)\n",
    "\tagg.columns = names\n",
    "\t# drop rows with NaN values\n",
    "\tif dropnan:\n",
    "\t\tagg.dropna(inplace=True)\n",
    "\treturn agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_cmapss(input_url):\n",
    "    df = pd.read_csv(\"input/dataset.csv\", header=None)\n",
    "    columns_old = [\"ENGINEID\", \"TIMECYCLE\", \"OPSET1\", \"OPSET2\", \"OPSET3\", \"Total temp at fan in (T2)\", \"Total temp at LPC out (T24)\", \"Total temp at HPC out (T30)\", \"Total temp at LPT out (T50)\", \n",
    "\"Pres at fan in (P2)\", \"Total pres in bypass-duct (P15)\", \"Total pres at HPC out (P30)\", \"Physical fan speed (Nf)\", \n",
    "\"Physical core speed (Nc)\", \"Engine pres ratio (epr=P50/P2)\", \"Static pres at HPC out (Ps30)\", \"Ratio of fuel flow to Ps30 (phi)\",\n",
    "\"Corrected fan speed (NRf)\", \"Corrected core speed (NRc)\", \"Bypass Ratio (BPR)\", \"Burner fuel-air ratio (farB)\", \n",
    "\"Bleed Enthalpy (htBleed)\", \"Demanded fan speed (Nf_dmd)\", \"Demanded corrected fan speed (PCNfR_dmd)\", \"HPT coolant bleed (W31)\",\n",
    "\"LPT coolant bleed (W32)\", \"FILEID\",\"RUL\"]\n",
    "    columns_new = [\"FILEID\",\"ENGINEID\", \"TIMECYCLE\", \"OPSET1\", \"OPSET2\", \"OPSET3\", \"Total temp at fan in (T2)\", \"Total temp at LPC out (T24)\", \"Total temp at HPC out (T30)\", \"Total temp at LPT out (T50)\", \n",
    "\"Pres at fan in (P2)\", \"Total pres in bypass-duct (P15)\", \"Total pres at HPC out (P30)\", \"Physical fan speed (Nf)\", \n",
    "\"Physical core speed (Nc)\", \"Engine pres ratio (epr=P50/P2)\", \"Static pres at HPC out (Ps30)\", \"Ratio of fuel flow to Ps30 (phi)\",\n",
    "\"Corrected fan speed (NRf)\", \"Corrected core speed (NRc)\", \"Bypass Ratio (BPR)\", \"Burner fuel-air ratio (farB)\", \n",
    "\"Bleed Enthalpy (htBleed)\", \"Demanded fan speed (Nf_dmd)\", \"Demanded corrected fan speed (PCNfR_dmd)\", \"HPT coolant bleed (W31)\",\n",
    "\"LPT coolant bleed (W32)\", \"RUL\"]\n",
    "    df.columns = columns_old\n",
    "    df = df[columns_new]\n",
    "\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_cmapss(input_url)\n",
    "feat_names = df.columns.values[3:-1]\n",
    "target_name = df.columns.values[-1]\n",
    "df[feat_names] = data_norm(df[feat_names])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_feat = [\"Total temp at HPC out (T30)\", \n",
    "               \"Total temp at LPT out (T50)\", \n",
    "               \"Physical core speed (Nc)\", \n",
    "               \"Static pres at HPC out (Ps30)\", \n",
    "               \"Corrected core speed (NRc)\", \n",
    "               \"Bypass Ratio (BPR)\", \n",
    "               \"Bleed Enthalpy (htBleed)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df[([\"FILEID\",\"ENGINEID\", \"TIMECYCLE\"]+select_feat+[\"RUL\"])][df.FILEID.isin([101, 103])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FILEID</th>\n",
       "      <th>ENGINEID</th>\n",
       "      <th>TIMECYCLE</th>\n",
       "      <th>Total temp at HPC out (T30)</th>\n",
       "      <th>Total temp at LPT out (T50)</th>\n",
       "      <th>Physical core speed (Nc)</th>\n",
       "      <th>Static pres at HPC out (Ps30)</th>\n",
       "      <th>Corrected core speed (NRc)</th>\n",
       "      <th>Bypass Ratio (BPR)</th>\n",
       "      <th>Bleed Enthalpy (htBleed)</th>\n",
       "      <th>RUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.046743</td>\n",
       "      <td>1.036938</td>\n",
       "      <td>0.991847</td>\n",
       "      <td>0.965896</td>\n",
       "      <td>0.641976</td>\n",
       "      <td>-0.842326</td>\n",
       "      <td>1.017912</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.064701</td>\n",
       "      <td>1.055603</td>\n",
       "      <td>0.986180</td>\n",
       "      <td>0.971745</td>\n",
       "      <td>0.552846</td>\n",
       "      <td>-0.825933</td>\n",
       "      <td>1.017912</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1.032258</td>\n",
       "      <td>1.063392</td>\n",
       "      <td>1.009890</td>\n",
       "      <td>0.907411</td>\n",
       "      <td>0.574597</td>\n",
       "      <td>-0.844592</td>\n",
       "      <td>0.953370</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>101</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.988211</td>\n",
       "      <td>1.046270</td>\n",
       "      <td>1.000641</td>\n",
       "      <td>0.866472</td>\n",
       "      <td>0.582098</td>\n",
       "      <td>-0.910696</td>\n",
       "      <td>1.017912</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>101</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.988719</td>\n",
       "      <td>1.078235</td>\n",
       "      <td>1.015798</td>\n",
       "      <td>0.910336</td>\n",
       "      <td>0.581723</td>\n",
       "      <td>-0.829132</td>\n",
       "      <td>1.050183</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   FILEID  ENGINEID  TIMECYCLE  Total temp at HPC out (T30)  \\\n",
       "0     101         1          1                     1.046743   \n",
       "1     101         1          2                     1.064701   \n",
       "2     101         1          3                     1.032258   \n",
       "3     101         1          4                     0.988211   \n",
       "4     101         1          5                     0.988719   \n",
       "\n",
       "   Total temp at LPT out (T50)  Physical core speed (Nc)  \\\n",
       "0                     1.036938                  0.991847   \n",
       "1                     1.055603                  0.986180   \n",
       "2                     1.063392                  1.009890   \n",
       "3                     1.046270                  1.000641   \n",
       "4                     1.078235                  1.015798   \n",
       "\n",
       "   Static pres at HPC out (Ps30)  Corrected core speed (NRc)  \\\n",
       "0                       0.965896                    0.641976   \n",
       "1                       0.971745                    0.552846   \n",
       "2                       0.907411                    0.574597   \n",
       "3                       0.866472                    0.582098   \n",
       "4                       0.910336                    0.581723   \n",
       "\n",
       "   Bypass Ratio (BPR)  Bleed Enthalpy (htBleed)  RUL  \n",
       "0           -0.842326                  1.017912  120  \n",
       "1           -0.825933                  1.017912  120  \n",
       "2           -0.844592                  0.953370  120  \n",
       "3           -0.910696                  1.017912  120  \n",
       "4           -0.829132                  1.050183  120  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM (Sibur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps = 30\n",
    "lag=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples length 163\n",
      "Targets length 163\n",
      "Samples length 163\n",
      "Targets length 163\n",
      "Samples length 258\n",
      "Targets length 258\n",
      "Samples length 150\n",
      "Targets length 150\n",
      "Samples length 160\n",
      "Targets length 160\n",
      "Samples length 240\n",
      "Targets length 240\n",
      "Samples length 159\n",
      "Targets length 159\n",
      "Samples length 230\n",
      "Targets length 230\n",
      "Samples length 121\n",
      "Targets length 121\n",
      "Samples length 172\n",
      "Targets length 172\n",
      "Samples length 193\n",
      "Targets length 193\n",
      "Samples length 211\n",
      "Targets length 211\n",
      "Samples length 141\n",
      "Targets length 141\n",
      "Samples length 134\n",
      "Targets length 134\n",
      "Samples length 151\n",
      "Targets length 151\n",
      "Samples length 178\n",
      "Targets length 178\n",
      "Samples length 180\n",
      "Targets length 180\n",
      "Samples length 247\n",
      "Targets length 247\n",
      "Samples length 166\n",
      "Targets length 166\n",
      "Samples length 129\n",
      "Targets length 129\n",
      "Samples length 205\n",
      "Targets length 205\n",
      "Samples length 166\n",
      "Targets length 166\n",
      "Samples length 173\n",
      "Targets length 173\n",
      "Samples length 139\n",
      "Targets length 139\n",
      "Samples length 118\n",
      "Targets length 118\n",
      "Samples length 201\n",
      "Targets length 201\n",
      "Samples length 170\n",
      "Targets length 170\n",
      "Samples length 127\n",
      "Targets length 127\n",
      "Samples length 136\n",
      "Targets length 136\n",
      "Samples length 134\n",
      "Targets length 134\n",
      "Samples length 165\n",
      "Targets length 165\n",
      "Samples length 205\n",
      "Targets length 205\n",
      "Samples length 162\n",
      "Targets length 162\n",
      "Samples length 171\n",
      "Targets length 171\n",
      "Samples length 166\n",
      "Targets length 166\n",
      "Samples length 152\n",
      "Targets length 152\n",
      "Samples length 129\n",
      "Targets length 129\n",
      "Samples length 141\n",
      "Targets length 141\n",
      "Samples length 165\n",
      "Targets length 165\n",
      "Samples length 99\n",
      "Targets length 99\n",
      "Samples length 159\n",
      "Targets length 159\n",
      "Samples length 187\n",
      "Targets length 187\n",
      "Samples length 167\n",
      "Targets length 167\n",
      "Samples length 178\n",
      "Targets length 178\n",
      "Samples length 163\n",
      "Targets length 163\n",
      "Samples length 129\n",
      "Targets length 129\n",
      "Samples length 227\n",
      "Targets length 227\n",
      "Samples length 185\n",
      "Targets length 185\n",
      "Samples length 202\n",
      "Targets length 202\n",
      "Samples length 186\n",
      "Targets length 186\n",
      "Samples length 169\n",
      "Targets length 169\n",
      "Samples length 184\n",
      "Targets length 184\n",
      "Samples length 184\n",
      "Targets length 184\n",
      "Samples length 166\n",
      "Targets length 166\n",
      "Samples length 228\n",
      "Targets length 228\n",
      "Samples length 164\n",
      "Targets length 164\n",
      "Samples length 246\n",
      "Targets length 246\n",
      "Samples length 108\n",
      "Targets length 108\n",
      "Samples length 118\n",
      "Targets length 118\n",
      "Samples length 202\n",
      "Targets length 202\n",
      "Samples length 143\n",
      "Targets length 143\n",
      "Samples length 156\n",
      "Targets length 156\n",
      "Samples length 151\n",
      "Targets length 151\n",
      "Samples length 145\n",
      "Targets length 145\n",
      "Samples length 254\n",
      "Targets length 254\n",
      "Samples length 124\n",
      "Targets length 124\n",
      "Samples length 173\n",
      "Targets length 173\n",
      "Samples length 284\n",
      "Targets length 284\n",
      "Samples length 170\n",
      "Targets length 170\n",
      "Samples length 333\n",
      "Targets length 333\n",
      "Samples length 108\n",
      "Targets length 108\n",
      "Samples length 179\n",
      "Targets length 179\n",
      "Samples length 184\n",
      "Targets length 184\n",
      "Samples length 184\n",
      "Targets length 184\n",
      "Samples length 137\n",
      "Targets length 137\n",
      "Samples length 200\n",
      "Targets length 200\n",
      "Samples length 181\n",
      "Targets length 181\n",
      "Samples length 125\n",
      "Targets length 125\n",
      "Samples length 202\n",
      "Targets length 202\n",
      "Samples length 170\n",
      "Targets length 170\n",
      "Samples length 156\n",
      "Targets length 156\n",
      "Samples length 211\n",
      "Targets length 211\n",
      "Samples length 185\n",
      "Targets length 185\n",
      "Samples length 264\n",
      "Targets length 264\n",
      "Samples length 238\n",
      "Targets length 238\n",
      "Samples length 159\n",
      "Targets length 159\n",
      "Samples length 249\n",
      "Targets length 249\n",
      "Samples length 149\n",
      "Targets length 149\n",
      "Samples length 184\n",
      "Targets length 184\n",
      "Samples length 188\n",
      "Targets length 188\n",
      "Samples length 125\n",
      "Targets length 125\n",
      "Samples length 106\n",
      "Targets length 106\n",
      "Samples length 312\n",
      "Targets length 312\n",
      "Samples length 126\n",
      "Targets length 126\n",
      "Samples length 229\n",
      "Targets length 229\n",
      "Samples length 254\n",
      "Targets length 254\n",
      "Samples length 307\n",
      "Targets length 307\n",
      "Samples length 173\n",
      "Targets length 173\n",
      "Samples length 127\n",
      "Targets length 127\n",
      "Samples length 156\n",
      "Targets length 156\n",
      "Samples length 171\n",
      "Targets length 171\n"
     ]
    }
   ],
   "source": [
    "eng_Xy_tuples = train[(train[\"FILEID\"]==101)].groupby(\"ENGINEID\").apply(lambda x:lstm_sampling(x.iloc[:,:-1], x.RUL, timesteps, lag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(eng_Xy_tuples[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
       "        14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,\n",
       "        27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,\n",
       "        40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,\n",
       "        53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
       "        66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,\n",
       "        79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
       "        92,  93,  94,  95,  96,  97,  98,  99, 100])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.ENGINEID.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "    Train = True\n",
    "    Predict = True\n",
    "    plot = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    batch_size = 1  # Batch size\n",
    "    shift = 1\n",
    "    #if Train == False: batch_size = 1\n",
    "\n",
    "    sequence_length = timesteps  # Number of steps\n",
    "    learning_rate = 2*10e-5  # 0.0001\n",
    "    epochs = 1000\n",
    "    ann_hidden = 16\n",
    "\n",
    "    n_channels = x_train.shape[2]\n",
    "\n",
    "    lstm_size = 48  # Number LSTM units\n",
    "    num_layers = 2  # 2  # Number of layers\n",
    "    alpha = 0 # regularization coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    X = tf.placeholder(tf.float32, [None, sequence_length, n_channels], name='inputs')\n",
    "    Y = tf.placeholder(tf.float32, [None, sequence_length], name='labels')\n",
    "    keep_prob = tf.placeholder(tf.float32, name='keep_prob')\n",
    "    learning_rate_ = tf.placeholder(tf.float32, name='learning_rate')\n",
    "    is_train = tf.placeholder(dtype=tf.bool, shape=None, name=\"is_train\")\n",
    "\n",
    "    conv_last_layer = X\n",
    "\n",
    "    shape = conv_last_layer.get_shape().as_list()\n",
    "    print('My Conv Shape:',shape)\n",
    "    CNN_flat = tf.reshape(conv_last_layer, [-1, shape[1] * shape[2]])\n",
    "\n",
    "    dence_layer_1 = dense_layer(CNN_flat, size=sequence_length * n_channels, activation_fn=tf.nn.relu, batch_norm=False,\n",
    "                                phase=is_train, drop_out=True, keep_prob=keep_prob,\n",
    "                                scope=\"fc_1\")\n",
    "    lstm_input = tf.reshape(dence_layer_1, [-1, sequence_length, n_channels])\n",
    "\n",
    "    cell = get_RNNCell(['LSTM'] * num_layers, keep_prob=keep_prob, state_size=lstm_size)\n",
    "    init_states = cell.zero_state(batch_size, tf.float32)\n",
    "    \n",
    "    # For each layer, get the initial state. states will be a tuple of LSTMStateTuples.\n",
    "    states = get_state_variables(batch_size, cell)\n",
    "\n",
    "    # Unroll the LSTM\n",
    "    rnn_output, new_states = tf.nn.dynamic_rnn(cell, lstm_input, dtype=tf.float32, initial_state=states)\n",
    "    \n",
    "    # Add an operation to update the train states with the last state tensors.\n",
    "    update_op = get_state_update_op(states, new_states)\n",
    "    reset_op = get_state_update_op(states, init_states)\n",
    "    \n",
    "    stacked_rnn_output = tf.reshape(rnn_output, [-1, lstm_size])  # change the form into a tensor\n",
    "\n",
    "    dence_layer_2 = dense_layer(stacked_rnn_output, size=ann_hidden, activation_fn=tf.nn.relu, batch_norm=False,\n",
    "                                phase=is_train, drop_out=True, keep_prob=keep_prob,\n",
    "                                scope=\"fc_2\")\n",
    "    \n",
    "    dence_layer_3 = dense_layer(dence_layer_2, size=ann_hidden, activation_fn=tf.nn.relu, batch_norm=False,\n",
    "                                phase=is_train, drop_out=True, keep_prob=keep_prob,\n",
    "                                scope=\"fc_2_2\")\n",
    "\n",
    "    output = dense_layer(dence_layer_3, size=1, activation_fn=None, batch_norm=False, phase=is_train, drop_out=False,\n",
    "                         keep_prob=keep_prob,\n",
    "                         scope=\"fc_3_output\")\n",
    "\n",
    "    prediction = tf.reshape(output, [-1])\n",
    "    y_flat = tf.reshape(Y, [-1])\n",
    "\n",
    "    h = prediction - y_flat\n",
    "    \n",
    "    tv = tf.trainable_variables()\n",
    "    regularization_cost = tf.reduce_sum([ tf.nn.l2_loss(v) for v in tv ])\n",
    "\n",
    "    cost_function = tf.reduce_sum(tf.square(h)) + alpha*regularization_cost\n",
    "    RMSE = tf.sqrt(tf.reduce_mean(tf.square(h)))\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate_).minimize(cost_function)\n",
    "\n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "    training_generator = batch_generator(x_train, y_train, batch_size, sequence_length, online=True, online_shift=shift)\n",
    "    testing_generator = batch_generator(x_test, y_test, batch_size, sequence_length, online=True, online_shift=shift)\n",
    "    #print(len(list(training_generator)))\n",
    "\n",
    "    if Train: model_summary(learning_rate=learning_rate, batch_size=batch_size, lstm_layers=num_layers,\n",
    "                            lstm_layer_size=lstm_size, fc_layer_size=ann_hidden, sequence_length=sequence_length,\n",
    "                            n_channels=n_channels, path_checkpoint=path_checkpoint, spacial_note='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TS fresh dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "check = train[(train[\"FILEID\"]==101) & (train[\"ENGINEID\"]==1)]\n",
    "X = check[check.columns.values[3:-1]]\n",
    "y = check[\"RUL\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps = 30\n",
    "lag=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples length 163\n",
      "Targets length 163\n"
     ]
    }
   ],
   "source": [
    "X, y = lstm_sampling(X, y, timesteps, lag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsfresh import select_features, extract_features\n",
    "from tsfresh.utilities.dataframe_functions import impute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[feat_names]\n",
    "y = df[target_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "test = df[df[\"FILEID\"]==101][df[\"ENGINEID\"]==1].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=test.drop([\"FILEID\", \"ENGINEID\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_lag_roll(df, feat_names, lag=1, step=1, roll=0):\n",
    "    x = series_to_supervised(test[feat_names], n_in=lag, n_out=1, periods=step)    \n",
    "    return pd.concat([df[lag:], x], axis=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "lag = 20\n",
    "step = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TIMECYCLE</th>\n",
       "      <th>OPSET1</th>\n",
       "      <th>OPSET2</th>\n",
       "      <th>OPSET3</th>\n",
       "      <th>Total temp at fan in (T2)</th>\n",
       "      <th>Total temp at LPC out (T24)</th>\n",
       "      <th>Total temp at HPC out (T30)</th>\n",
       "      <th>Total temp at LPT out (T50)</th>\n",
       "      <th>Pres at fan in (P2)</th>\n",
       "      <th>Total pres in bypass-duct (P15)</th>\n",
       "      <th>...</th>\n",
       "      <th>var15(t-2)</th>\n",
       "      <th>var16(t-2)</th>\n",
       "      <th>var17(t-2)</th>\n",
       "      <th>var18(t-2)</th>\n",
       "      <th>var19(t-2)</th>\n",
       "      <th>var20(t-2)</th>\n",
       "      <th>var21(t-2)</th>\n",
       "      <th>var22(t-2)</th>\n",
       "      <th>var23(t-2)</th>\n",
       "      <th>var24(t-2)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>-1.042166</td>\n",
       "      <td>-1.114839</td>\n",
       "      <td>0.34552</td>\n",
       "      <td>1.079737</td>\n",
       "      <td>1.061976</td>\n",
       "      <td>1.015995</td>\n",
       "      <td>1.018788</td>\n",
       "      <td>1.108381</td>\n",
       "      <td>1.115795</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003229</td>\n",
       "      <td>-0.00045</td>\n",
       "      <td>-0.061129</td>\n",
       "      <td>0.036251</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.032271</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.024797</td>\n",
       "      <td>0.005173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>-1.042081</td>\n",
       "      <td>-1.115110</td>\n",
       "      <td>0.34552</td>\n",
       "      <td>1.079737</td>\n",
       "      <td>1.071397</td>\n",
       "      <td>1.074104</td>\n",
       "      <td>1.036718</td>\n",
       "      <td>1.108381</td>\n",
       "      <td>1.115795</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000426</td>\n",
       "      <td>-0.00009</td>\n",
       "      <td>-0.008751</td>\n",
       "      <td>0.023456</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009406</td>\n",
       "      <td>0.006099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>-1.041887</td>\n",
       "      <td>-1.115926</td>\n",
       "      <td>0.34552</td>\n",
       "      <td>1.079737</td>\n",
       "      <td>1.056559</td>\n",
       "      <td>1.033953</td>\n",
       "      <td>0.993951</td>\n",
       "      <td>1.108381</td>\n",
       "      <td>1.115795</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005482</td>\n",
       "      <td>0.00027</td>\n",
       "      <td>0.076505</td>\n",
       "      <td>-0.025455</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012826</td>\n",
       "      <td>-0.020820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>-1.042153</td>\n",
       "      <td>-1.114295</td>\n",
       "      <td>0.34552</td>\n",
       "      <td>1.079737</td>\n",
       "      <td>1.062211</td>\n",
       "      <td>1.056315</td>\n",
       "      <td>1.023785</td>\n",
       "      <td>1.108381</td>\n",
       "      <td>1.115795</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000792</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-0.043378</td>\n",
       "      <td>0.019058</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.006840</td>\n",
       "      <td>0.001368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>-1.041954</td>\n",
       "      <td>-1.116197</td>\n",
       "      <td>0.34552</td>\n",
       "      <td>1.079737</td>\n",
       "      <td>1.071397</td>\n",
       "      <td>1.084014</td>\n",
       "      <td>1.028047</td>\n",
       "      <td>1.108381</td>\n",
       "      <td>1.115795</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006335</td>\n",
       "      <td>0.00027</td>\n",
       "      <td>-0.108882</td>\n",
       "      <td>0.043048</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.032271</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000855</td>\n",
       "      <td>0.003905</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 264 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    TIMECYCLE    OPSET1    OPSET2   OPSET3  Total temp at fan in (T2)  \\\n",
       "20         21 -1.042166 -1.114839  0.34552                   1.079737   \n",
       "21         22 -1.042081 -1.115110  0.34552                   1.079737   \n",
       "22         23 -1.041887 -1.115926  0.34552                   1.079737   \n",
       "23         24 -1.042153 -1.114295  0.34552                   1.079737   \n",
       "24         25 -1.041954 -1.116197  0.34552                   1.079737   \n",
       "\n",
       "    Total temp at LPC out (T24)  Total temp at HPC out (T30)  \\\n",
       "20                     1.061976                     1.015995   \n",
       "21                     1.071397                     1.074104   \n",
       "22                     1.056559                     1.033953   \n",
       "23                     1.062211                     1.056315   \n",
       "24                     1.071397                     1.084014   \n",
       "\n",
       "    Total temp at LPT out (T50)  Pres at fan in (P2)  \\\n",
       "20                     1.018788             1.108381   \n",
       "21                     1.036718             1.108381   \n",
       "22                     0.993951             1.108381   \n",
       "23                     1.023785             1.108381   \n",
       "24                     1.028047             1.108381   \n",
       "\n",
       "    Total pres in bypass-duct (P15)     ...      var15(t-2)  var16(t-2)  \\\n",
       "20                         1.115795     ...       -0.003229    -0.00045   \n",
       "21                         1.115795     ...        0.000426    -0.00009   \n",
       "22                         1.115795     ...        0.005482     0.00027   \n",
       "23                         1.115795     ...       -0.000792     0.00000   \n",
       "24                         1.115795     ...       -0.006335     0.00027   \n",
       "\n",
       "    var17(t-2)  var18(t-2)  var19(t-2)  var20(t-2)  var21(t-2)  var22(t-2)  \\\n",
       "20   -0.061129    0.036251         0.0   -0.032271         0.0         0.0   \n",
       "21   -0.008751    0.023456         0.0    0.000000         0.0         0.0   \n",
       "22    0.076505   -0.025455         0.0    0.000000         0.0         0.0   \n",
       "23   -0.043378    0.019058         0.0    0.000000         0.0         0.0   \n",
       "24   -0.108882    0.043048         0.0   -0.032271         0.0         0.0   \n",
       "\n",
       "    var23(t-2)  var24(t-2)  \n",
       "20   -0.024797    0.005173  \n",
       "21    0.009406    0.006099  \n",
       "22    0.012826   -0.020820  \n",
       "23   -0.006840    0.001368  \n",
       "24   -0.000855    0.003905  \n",
       "\n",
       "[5 rows x 264 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_lag_roll(test.iloc[:,:-2], feat_names, lag=lag, step=step, roll=0).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.groupby([\"FILEID\", \"ENGINEID\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X=pd.DataFrame()\n",
    "#y=list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for name, group in df.groupby([\"FILEID\", \"ENGINEID\"]):\n",
    "    #X = pd.concat([X, add_lag_roll(group[feat_names], feat_names, lag=lag, step=step)], axis=0)\n",
    "    #y = y.append(group[\"RUL\"][lag:])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.07587484,  1.16808529,  0.34551956, -1.19585285, -0.96277102,\n",
       "        -0.74158237, -0.87287892, -1.03437167, -0.99635436, -0.94961297,\n",
       "        -0.35376305, -0.75431935, -0.93920659, -0.61027389, -0.95498265,\n",
       "         0.35008025,  0.13632058,  0.45963462, -1.02579284, -0.8215301 ,\n",
       "        -0.35667189,  0.34551956, -0.9598422 , -0.95726673]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.tail(1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
